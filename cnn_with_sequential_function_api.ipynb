{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (50000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 1)\n",
      "Shape of X_test: (10000, 32, 32, 3)\n",
      "Shape of y_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 50000 training samples and 10000 test samples\n",
    "# 32x32 image size and 3 channels\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (defualt)padding = valid will make image dimensions smaller and padding = same will make image dimensions same as input\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape = (32, 32, 3)), # maintain the shape of the input instead of flattening it to 1D array\n",
    "        layers.Conv2D(32, 3, padding = 'valid', activation = 'relu'), # 32 channels, 3x3 kernel size, valid padding\n",
    "        layers.MaxPooling2D(pool_size = (2, 2)), # 2x2 pooling size\n",
    "        layers.Conv2D(64, 3, activation = 'relu'),\n",
    "        layers.MaxPooling2D(), # defualt pool size is 2x2\n",
    "        layers.Conv2D(128, 3, activation = 'relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation = 'relu'), # 1 internmediate layer\n",
    "        layers.Dense(10) # 10 output classes\n",
    "        \n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), # no softmax activation mentioned in the last layer while buidling the model so we need to use from_logits = True\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
    "    metrics = ['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 27s 22ms/step - loss: 1.6503 - accuracy: 0.3927\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.3402 - accuracy: 0.5188\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.2128 - accuracy: 0.5709\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.1120 - accuracy: 0.6109\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 1.0389 - accuracy: 0.6388\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.9732 - accuracy: 0.6616\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.9212 - accuracy: 0.6796\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 0.8711 - accuracy: 0.6967\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.8277 - accuracy: 0.7121\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.7897 - accuracy: 0.7268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17196778be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 64, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 8ms/step - loss: 0.8733 - accuracy: 0.6937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8732865452766418, 0.6937000155448914]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = 64, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcitonal TF API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    inputs = keras.Input(shape = (32, 32, 3)) \n",
    "    x = layers.Conv2D(32, 3)(inputs) # layer 1, default padding is valid\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 5, padding = \"same\")(x) # layer 2\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Conv2D(128, 3)(x) # layer 3\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation = 'relu')(x) # layer 4\n",
    "    outputs = layers.Dense(10)(x) # output layer \n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = outputs, name = \"cnn_model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile, fit and evaluate are same as sequential API method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
    "    metrics = ['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 15s 17ms/step - loss: 1.2867 - accuracy: 0.5415\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.8833 - accuracy: 0.6916\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.7256 - accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.6131 - accuracy: 0.7839\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 26s 33ms/step - loss: 0.5232 - accuracy: 0.8160\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.4395 - accuracy: 0.8478\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.3700 - accuracy: 0.8732\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 18s 22ms/step - loss: 0.3031 - accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.2422 - accuracy: 0.9196\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 0.2002 - accuracy: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x171a2b10a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 64, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 4s 19ms/step - loss: 1.0542 - accuracy: 0.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0541561841964722, 0.7135000228881836]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = 64, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We notice that training accuracy is 93% and test accuracy is 71%\n",
    "\n",
    "- solution: Regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add regularization to the each layer\n",
    "# bacthnormalization is used to normalize the output of the previous layer and also has regularizing affect\n",
    "\n",
    "def cnn_model_with_reg():\n",
    "    inputs = keras.Input(shape = (32, 32, 3)) \n",
    "    x = layers.Conv2D(32, 3, padding = \"same\", kernel_regularizer = regularizers.l2(0.01),)(inputs)  # layer 1, default padding is valid\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 5, padding = \"same\", kernel_regularizer = regularizers.l2(0.01),)(x) # layer 2\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Conv2D(128, 3,  padding = \"same\", kernel_regularizer = regularizers.l2(0.01))(x) # layer 3\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.l2(0.01))(x) # layer 4\n",
    "    x = layers.Dropout(0.5)(x) # dropout takes longer to train\n",
    "    outputs = layers.Dense(10)(x) # output layer \n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = outputs, name = \"cnn_model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = cnn_model_with_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
    "    metrics = ['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 2.5260 - accuracy: 0.1691\n",
      "Epoch 2/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 2.1823 - accuracy: 0.2004\n",
      "Epoch 3/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 2.0799 - accuracy: 0.2285\n",
      "Epoch 4/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 2.0300 - accuracy: 0.2385\n",
      "Epoch 5/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.9904 - accuracy: 0.2494\n",
      "Epoch 6/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.9607 - accuracy: 0.2550\n",
      "Epoch 7/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.9507 - accuracy: 0.2574\n",
      "Epoch 8/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.9423 - accuracy: 0.2626\n",
      "Epoch 9/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.9392 - accuracy: 0.2604\n",
      "Epoch 10/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.9321 - accuracy: 0.2662\n",
      "Epoch 11/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.9097 - accuracy: 0.2766\n",
      "Epoch 12/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.9021 - accuracy: 0.2827\n",
      "Epoch 13/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8902 - accuracy: 0.2917\n",
      "Epoch 14/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.8828 - accuracy: 0.2955\n",
      "Epoch 15/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8678 - accuracy: 0.3052\n",
      "Epoch 16/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.8722 - accuracy: 0.3008\n",
      "Epoch 17/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.8693 - accuracy: 0.3037\n",
      "Epoch 18/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.8645 - accuracy: 0.3020\n",
      "Epoch 19/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8591 - accuracy: 0.3072\n",
      "Epoch 20/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.8553 - accuracy: 0.3075\n",
      "Epoch 21/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.8546 - accuracy: 0.3094\n",
      "Epoch 22/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8462 - accuracy: 0.3172\n",
      "Epoch 23/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8512 - accuracy: 0.3123\n",
      "Epoch 24/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.8483 - accuracy: 0.3122\n",
      "Epoch 25/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8477 - accuracy: 0.3112\n",
      "Epoch 26/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.8348 - accuracy: 0.3173\n",
      "Epoch 27/150\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.8319 - accuracy: 0.3191\n",
      "Epoch 28/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8345 - accuracy: 0.3180\n",
      "Epoch 29/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8300 - accuracy: 0.3239\n",
      "Epoch 30/150\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 1.8274 - accuracy: 0.3236\n",
      "Epoch 31/150\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 1.8333 - accuracy: 0.3196\n",
      "Epoch 32/150\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.8233 - accuracy: 0.3253\n",
      "Epoch 33/150\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 1.8210 - accuracy: 0.3232\n",
      "Epoch 34/150\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.8220 - accuracy: 0.3270\n",
      "Epoch 35/150\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.8188 - accuracy: 0.3253\n",
      "Epoch 36/150\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 1.8209 - accuracy: 0.3269\n",
      "Epoch 37/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8189 - accuracy: 0.3285\n",
      "Epoch 38/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8176 - accuracy: 0.3284\n",
      "Epoch 39/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8159 - accuracy: 0.3328\n",
      "Epoch 40/150\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.8162 - accuracy: 0.3319\n",
      "Epoch 41/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8185 - accuracy: 0.3309\n",
      "Epoch 42/150\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.8136 - accuracy: 0.3297\n",
      "Epoch 43/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.8078 - accuracy: 0.3339\n",
      "Epoch 44/150\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.8126 - accuracy: 0.3341\n",
      "Epoch 45/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.8094 - accuracy: 0.3348\n",
      "Epoch 46/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.8074 - accuracy: 0.3348\n",
      "Epoch 47/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.8066 - accuracy: 0.3362\n",
      "Epoch 48/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.8048 - accuracy: 0.3397\n",
      "Epoch 49/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.8064 - accuracy: 0.3358\n",
      "Epoch 50/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7998 - accuracy: 0.3373\n",
      "Epoch 51/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.8012 - accuracy: 0.3350\n",
      "Epoch 52/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7992 - accuracy: 0.3395\n",
      "Epoch 53/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7932 - accuracy: 0.3404\n",
      "Epoch 54/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7999 - accuracy: 0.3404\n",
      "Epoch 55/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.8020 - accuracy: 0.3388\n",
      "Epoch 56/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7945 - accuracy: 0.3409\n",
      "Epoch 57/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7924 - accuracy: 0.3430\n",
      "Epoch 58/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7942 - accuracy: 0.3420\n",
      "Epoch 59/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7924 - accuracy: 0.3455\n",
      "Epoch 60/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7903 - accuracy: 0.3451\n",
      "Epoch 61/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7875 - accuracy: 0.3441\n",
      "Epoch 62/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7950 - accuracy: 0.3437\n",
      "Epoch 63/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7859 - accuracy: 0.3450\n",
      "Epoch 64/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7913 - accuracy: 0.3445\n",
      "Epoch 65/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7887 - accuracy: 0.3444\n",
      "Epoch 66/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7882 - accuracy: 0.3445\n",
      "Epoch 67/150\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7898 - accuracy: 0.3431\n",
      "Epoch 68/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7885 - accuracy: 0.3449\n",
      "Epoch 69/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7849 - accuracy: 0.3465\n",
      "Epoch 70/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7861 - accuracy: 0.3468\n",
      "Epoch 71/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7915 - accuracy: 0.3457\n",
      "Epoch 72/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7875 - accuracy: 0.3463\n",
      "Epoch 73/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7905 - accuracy: 0.3453\n",
      "Epoch 74/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7806 - accuracy: 0.3489\n",
      "Epoch 75/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7880 - accuracy: 0.3459\n",
      "Epoch 76/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7909 - accuracy: 0.3444\n",
      "Epoch 77/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7902 - accuracy: 0.3466\n",
      "Epoch 78/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7847 - accuracy: 0.3478\n",
      "Epoch 79/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7806 - accuracy: 0.3521\n",
      "Epoch 80/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7806 - accuracy: 0.3477\n",
      "Epoch 81/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7872 - accuracy: 0.3448\n",
      "Epoch 82/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7856 - accuracy: 0.3504\n",
      "Epoch 83/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7788 - accuracy: 0.3513\n",
      "Epoch 84/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7797 - accuracy: 0.3514\n",
      "Epoch 85/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7878 - accuracy: 0.3451\n",
      "Epoch 86/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7725 - accuracy: 0.3532\n",
      "Epoch 87/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7810 - accuracy: 0.3488\n",
      "Epoch 88/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7802 - accuracy: 0.3511\n",
      "Epoch 89/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7833 - accuracy: 0.3482\n",
      "Epoch 90/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7835 - accuracy: 0.3476\n",
      "Epoch 91/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7766 - accuracy: 0.3517\n",
      "Epoch 92/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7764 - accuracy: 0.3535\n",
      "Epoch 93/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7831 - accuracy: 0.3499\n",
      "Epoch 94/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7853 - accuracy: 0.3474\n",
      "Epoch 95/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7848 - accuracy: 0.3456\n",
      "Epoch 96/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7760 - accuracy: 0.3521\n",
      "Epoch 97/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7828 - accuracy: 0.3499\n",
      "Epoch 98/150\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7812 - accuracy: 0.3496\n",
      "Epoch 99/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7857 - accuracy: 0.3488\n",
      "Epoch 100/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7800 - accuracy: 0.3514\n",
      "Epoch 101/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7780 - accuracy: 0.3517\n",
      "Epoch 102/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7779 - accuracy: 0.3503\n",
      "Epoch 103/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7743 - accuracy: 0.3499\n",
      "Epoch 104/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7809 - accuracy: 0.3485\n",
      "Epoch 105/150\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7711 - accuracy: 0.3502\n",
      "Epoch 106/150\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7761 - accuracy: 0.3508\n",
      "Epoch 107/150\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7785 - accuracy: 0.3503\n",
      "Epoch 108/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7817 - accuracy: 0.3499\n",
      "Epoch 109/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7715 - accuracy: 0.3527\n",
      "Epoch 110/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7764 - accuracy: 0.3514\n",
      "Epoch 111/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7798 - accuracy: 0.3541\n",
      "Epoch 112/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7744 - accuracy: 0.3528\n",
      "Epoch 113/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7673 - accuracy: 0.3541\n",
      "Epoch 114/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7684 - accuracy: 0.3545\n",
      "Epoch 115/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7721 - accuracy: 0.3537\n",
      "Epoch 116/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7697 - accuracy: 0.3577\n",
      "Epoch 117/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7738 - accuracy: 0.3542\n",
      "Epoch 118/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7681 - accuracy: 0.3559\n",
      "Epoch 119/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7722 - accuracy: 0.3546\n",
      "Epoch 120/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7678 - accuracy: 0.3546\n",
      "Epoch 121/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7700 - accuracy: 0.3579\n",
      "Epoch 122/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7696 - accuracy: 0.3561\n",
      "Epoch 123/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7644 - accuracy: 0.3580\n",
      "Epoch 124/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7715 - accuracy: 0.3539\n",
      "Epoch 125/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7700 - accuracy: 0.3547\n",
      "Epoch 126/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7775 - accuracy: 0.3522\n",
      "Epoch 127/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7753 - accuracy: 0.3526\n",
      "Epoch 128/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7740 - accuracy: 0.3541\n",
      "Epoch 129/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7674 - accuracy: 0.3541\n",
      "Epoch 130/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7714 - accuracy: 0.3555\n",
      "Epoch 131/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7643 - accuracy: 0.3577\n",
      "Epoch 132/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7679 - accuracy: 0.3562\n",
      "Epoch 133/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7684 - accuracy: 0.3571\n",
      "Epoch 134/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7672 - accuracy: 0.3543\n",
      "Epoch 135/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7707 - accuracy: 0.3549\n",
      "Epoch 136/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7760 - accuracy: 0.3532\n",
      "Epoch 137/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7714 - accuracy: 0.3531\n",
      "Epoch 138/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7645 - accuracy: 0.3565\n",
      "Epoch 139/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7706 - accuracy: 0.3543\n",
      "Epoch 140/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7768 - accuracy: 0.3531\n",
      "Epoch 141/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7673 - accuracy: 0.3550\n",
      "Epoch 142/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7673 - accuracy: 0.3556\n",
      "Epoch 143/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7673 - accuracy: 0.3553\n",
      "Epoch 144/150\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7683 - accuracy: 0.3563\n",
      "Epoch 145/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7643 - accuracy: 0.3553\n",
      "Epoch 146/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7730 - accuracy: 0.3539\n",
      "Epoch 147/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7680 - accuracy: 0.3518\n",
      "Epoch 148/150\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.7654 - accuracy: 0.3557\n",
      "Epoch 149/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7613 - accuracy: 0.3572\n",
      "Epoch 150/150\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 1.7747 - accuracy: 0.3527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172594f8dc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running for more epochs\n",
    "\n",
    "model_reg.fit(X_train, y_train, batch_size = 64, epochs = 150, verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 9ms/step - loss: 1.5183 - accuracy: 0.5059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5183371305465698, 0.5059000253677368]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.evaluate(X_test, y_test, batch_size = 64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
