{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ignore unimportant msgs from tensorflow\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13961599702222817789\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2909221684\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16760494393356069578\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device found\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU device found\")\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "else:\n",
    "    print(\"No GPU device found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train is: (60000, 28, 28)\n",
      "Shape of y_train is:(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_train is: {X_train.shape}\")\n",
    "print(f\"Shape of y_train is:{y_train.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To send images of size 28*28 to NN, we need to flatten them into 1D array, i.e. convert size from 28*28 = 784.\n",
    "- This is create one column which we can pass to NN for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 keeps the same number of rows(60000) in the X_train dimension (60000, 28, 28)\n",
    "# flatten to 1D array and normalize to 0-1 by deviding by 255\n",
    "X_train = X_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "\n",
    "# to the same for the test set\n",
    "X_test = X_test.reshape(-1, 28*28).astype(\"float32\") / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In TF, it automatically converts numpy arrays to tensors internally, so we don't have to worry about it.\n",
    "\n",
    "- no need to write this: X_train = tf.convert_to_tensor(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API (Very convenient, not very flexible)\n",
    "\n",
    "- **Major Limitation:** It only allows you to have 1 input mapped to 1 output\n",
    "\n",
    "- So, use only when you have 1 input and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected neural network\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28*28)), # input layer; useful for printing model summary\n",
    "        layers.Dense(512, activation=\"relu\"), # first layer\n",
    "        layers.Dense(256, activation=\"relu\"), # second layer\n",
    "        layers.Dense(10), # one node for each digit\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model.compile: tell keras how to configure the training part of NN.\n",
    "- Ex: Here we can specify the loss function\n",
    "\n",
    "- **Note:** \n",
    "1) Use sparse categorical crossentropy when your classes are mutually exclusive (e.g. when each sample belongs exactly to one class) and categorical crossentropy when one sample can have multiple classes or labels are soft probabilities (like [0.5, 0.3, 0.2]).\n",
    "\n",
    "2) If your targets are one-hot encoded, use categorical_crossentropy. But if your targets are integers, use sparse_categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifiy the NN config like loss, optimizer, metrics\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), # softmax activation then map to sparse categorical crossentropy\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = [\"accuracy\"],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 11s - loss: 0.1850 - accuracy: 0.9446 - 11s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "1875/1875 - 10s - loss: 0.0798 - accuracy: 0.9747 - 10s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "1875/1875 - 11s - loss: 0.0544 - accuracy: 0.9822 - 11s/epoch - 6ms/step\n",
      "Epoch 4/5\n",
      "1875/1875 - 11s - loss: 0.0398 - accuracy: 0.9870 - 11s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "1875/1875 - 9s - loss: 0.0331 - accuracy: 0.9896 - 9s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b5d1dff400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbose = 2, print the loss and accuracy for each epoch\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0799 - accuracy: 0.9774 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0799143835902214, 0.977400004863739]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = 32, verbose = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to add layers sequentially\n",
    "\n",
    "- This method is useful to print model summary after adding each layer (useful for debugging layer by layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,920\n",
      "Trainable params: 401,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " my_layer (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,248\n",
      "Trainable params: 533,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape = (28*28)))\n",
    "model.add(layers.Dense(512, activation = \"relu\"))\n",
    "model.summary() # print the model summary\n",
    "model.add(layers.Dense(256, activation = \"relu\", name = \"my_layer\"))\n",
    "model.summary() # print the model summary\n",
    "model.add(layers.Dense(10, activation = \"softmax\")) # final layer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to extract specific layer outputs, useful for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get spefic layer output\n",
    "# model = keras.Model(inputs = model.inputs, outputs = [model.layers[-2].out])\n",
    "# or use below code\n",
    "model = keras.Model(inputs = model.inputs, outputs = [model.get_layer(\"my_layer\").output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to get all the layers output then use below code\n",
    "# model = keras.Model(inputs = model.inputs, outputs = [layer.output for layer in model.layers])\n",
    "\n",
    "# # here we get all the features from the model\n",
    "# features = model.predict(X_train)\n",
    "\n",
    "# for feature in features:\n",
    "#     print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "feature = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtional API (A bit more flexible)\n",
    "\n",
    "- Can handle multiple inputs and multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (28*28))\n",
    "x = layers.Dense(512, activation = \"relu\", name = \"first_layer\")(inputs) # call the layer on the input\n",
    "x = layers.Dense(256, activation = \"relu\", name = \"second_layer\")(x) # call the layer on the output of the previous layer\n",
    "outputs = layers.Dense(10, activation = \"softmax\")(x) # call the layer on the output of the previous layer\n",
    "model = keras.Model(inputs = inputs, outputs = outputs, name = \"mnist_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifiy the NN config like loss, optimizer, metrics\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we already mentioned softmax activation in the last layer. By default, from_logits is False\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = [\"accuracy\"],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1851 - accuracy: 0.9445\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0794 - accuracy: 0.9747\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0555 - accuracy: 0.9828\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0405 - accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0339 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b58167e400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbose = 1, print the loss and accuracy for each epoch with an animated progress bar\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0780 - accuracy: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07802246510982513, 0.9790999889373779]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
